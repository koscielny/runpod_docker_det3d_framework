#!/usr/bin/env python3
"""
VADèµ„æºä¸‹è½½è„šæœ¬
è‡ªåŠ¨ä¸‹è½½VADé¡¹ç›®æ‰€éœ€çš„æ¨¡å‹æƒé‡ã€æ•°æ®é›†æ³¨é‡Šæ–‡ä»¶å’Œé¢„è®­ç»ƒæƒé‡
"""

import os
import sys
import subprocess
import urllib.request
from pathlib import Path

def install_gdown():
    """å®‰è£…gdownåŒ…"""
    try:
        import gdown
        print("âœ… gdown already installed")
    except ImportError:
        print("ğŸ“¦ Installing gdown...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "gdown"])
        import gdown
        print("âœ… gdown installed successfully")

def create_directories(base_path):
    """åˆ›å»ºç›®å½•ç»“æ„"""
    directories = {
        'models': base_path / 'models',
        'pretrained': base_path / 'pretrained', 
        'nuscenes_annotations': base_path / 'nuscenes_annotations',
        'datasets': base_path / 'datasets'
    }
    
    for name, path in directories.items():
        path.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ Created directory: {path}")
    
    return directories

def download_from_gdrive(file_id, output_path, description):
    """ä»Google Driveä¸‹è½½æ–‡ä»¶"""
    try:
        import gdown
        url = f"https://drive.google.com/uc?id={file_id}"
        print(f"â¬‡ï¸  Downloading {description}...")
        print(f"   URL: {url}")
        print(f"   Output: {output_path}")
        
        gdown.download(url, str(output_path), quiet=False)
        
        if output_path.exists():
            file_size = output_path.stat().st_size / (1024*1024)  # MB
            print(f"âœ… Downloaded {description} ({file_size:.1f} MB)")
            return True
        else:
            print(f"âŒ Failed to download {description}")
            return False
            
    except Exception as e:
        print(f"âŒ Error downloading {description}: {e}")
        return False

def download_from_url(url, output_path, description):
    """ä»æ™®é€šURLä¸‹è½½æ–‡ä»¶"""
    try:
        print(f"â¬‡ï¸  Downloading {description}...")
        print(f"   URL: {url}")
        print(f"   Output: {output_path}")
        
        urllib.request.urlretrieve(url, str(output_path))
        
        if output_path.exists():
            file_size = output_path.stat().st_size / (1024*1024)  # MB
            print(f"âœ… Downloaded {description} ({file_size:.1f} MB)")
            return True
        else:
            print(f"âŒ Failed to download {description}")
            return False
            
    except Exception as e:
        print(f"âŒ Error downloading {description}: {e}")
        return False

def main():
    # è®¾ç½®åŸºç¡€è·¯å¾„ - ä¼˜å…ˆä½¿ç”¨/workspaceï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨å½“å‰ç›®å½•
    if Path('/workspace').exists():
        base_path = Path('/workspace/data/vad_demo')
    else:
        # ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç›¸å¯¹è·¯å¾„
        script_dir = Path(__file__).parent
        base_path = script_dir / '../../data/vad_demo'
        base_path = base_path.resolve()  # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    
    print(f"ğŸ¯ VADèµ„æºä¸‹è½½è„šæœ¬")
    print(f"ğŸ“‚ Base directory: {base_path}")
    
    # å®‰è£…gdown
    install_gdown()
    
    # åˆ›å»ºç›®å½•ç»“æ„
    dirs = create_directories(base_path)
    
    # å®šä¹‰ä¸‹è½½èµ„æº
    downloads = [
        # VADæ¨¡å‹æƒé‡
        {
            'type': 'gdrive',
            'file_id': '1KgCC_wFqPH0CQqdr6Pp2smBX5ARPaqne',
            'output': dirs['models'] / 'vad_tiny_stage_2.pth',
            'description': 'VAD-Tiny Model (R50 backbone)'
        },
        {
            'type': 'gdrive', 
            'file_id': '1FLX-4LVm4z-RskghFbxGuYlcYOQmV5bS',
            'output': dirs['models'] / 'vad_base_stage_2.pth',
            'description': 'VAD-Base Model (R50 backbone)'
        },
        
        # nuScenesæ³¨é‡Šæ–‡ä»¶
        {
            'type': 'gdrive',
            'file_id': '1OVd6Rw2wYjT_ylihCixzF6_olrAQsctx',
            'output': dirs['nuscenes_annotations'] / 'vad_nuscenes_infos_temporal_train.pkl',
            'description': 'nuScenes Train Annotations'
        },
        {
            'type': 'gdrive',
            'file_id': '16DZeA-iepMCaeyi57XSXL3vYyhrOQI9S', 
            'output': dirs['nuscenes_annotations'] / 'vad_nuscenes_infos_temporal_val.pkl',
            'description': 'nuScenes Val Annotations'
        },
        
        # é¢„è®­ç»ƒæƒé‡
        {
            'type': 'url',
            'url': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
            'output': dirs['pretrained'] / 'resnet50-19c8e357.pth',
            'description': 'ResNet50 Pretrained Weights'
        }
    ]
    
    # æ‰§è¡Œä¸‹è½½
    success_count = 0
    total_count = len(downloads)
    
    print(f"\nğŸš€ Starting downloads ({total_count} files)...")
    print("="*60)
    
    for i, item in enumerate(downloads, 1):
        print(f"\n[{i}/{total_count}] {item['description']}")
        print("-" * 40)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if item['output'].exists():
            file_size = item['output'].stat().st_size / (1024*1024)  # MB
            print(f"âš ï¸  File already exists ({file_size:.1f} MB), skipping...")
            success_count += 1
            continue
        
        # æ‰§è¡Œä¸‹è½½
        if item['type'] == 'gdrive':
            success = download_from_gdrive(
                item['file_id'], 
                item['output'], 
                item['description']
            )
        elif item['type'] == 'url':
            success = download_from_url(
                item['url'],
                item['output'], 
                item['description']
            )
        
        if success:
            success_count += 1
    
    # è¾“å‡ºç»“æœç»Ÿè®¡
    print("\n" + "="*60)
    print(f"ğŸ“Š Download Summary:")
    print(f"   âœ… Successful: {success_count}/{total_count}")
    print(f"   âŒ Failed: {total_count - success_count}/{total_count}")
    
    if success_count == total_count:
        print(f"ğŸ‰ All files downloaded successfully!")
    else:
        print(f"âš ï¸  Some downloads failed. Please check the logs above.")
    
    # æ˜¾ç¤ºç›®å½•ç»“æ„
    print(f"\nğŸ“ Final directory structure:")
    for name, path in dirs.items():
        files = list(path.glob('*'))
        print(f"   {name}: {len(files)} files in {path}")
        for file in files:
            file_size = file.stat().st_size / (1024*1024)  # MB
            print(f"      - {file.name} ({file_size:.1f} MB)")

if __name__ == "__main__":
    main()