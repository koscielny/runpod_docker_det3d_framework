# è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ä¸‹è½½å’Œæ•´ç†æŒ‡å—

æœ¬æ–‡æ¡£æä¾›äº† nuScenesã€Waymo Open Dataset å’Œ Argoverse æ•°æ®é›†çš„ä¸‹è½½å’Œæ•´ç†æ–¹æ³•ï¼Œç‰¹åˆ«å…³æ³¨å°å‹éªŒè¯å­é›†çš„è·å–ï¼Œé€‚ç”¨äºæ¨¡å‹éªŒè¯å’Œè°ƒè¯•è¯„ä¼°æµæ°´çº¿ã€‚

## ç›®å½•
- [nuScenes æ•°æ®é›†](#nuscenes-æ•°æ®é›†)
- [Waymo Open Dataset](#waymo-open-dataset)
- [Argoverse æ•°æ®é›†](#argoverse-æ•°æ®é›†)
- [ç»Ÿä¸€æ•°æ®ç®¡ç†è„šæœ¬](#ç»Ÿä¸€æ•°æ®ç®¡ç†è„šæœ¬)
- [å­˜å‚¨ç©ºé—´è§„åˆ’](#å­˜å‚¨ç©ºé—´è§„åˆ’)

---

## nuScenes æ•°æ®é›†

### ğŸ“‹ **æ•°æ®é›†æ¦‚è¿°**
- **å‘å¸ƒæ–¹**: nuTonomy (ç°ä¸º Motional)
- **æ•°æ®ç±»å‹**: 3D æ£€æµ‹ã€è·Ÿè¸ªã€é¢„æµ‹ã€åœ°å›¾é‡å»º
- **ä¼ æ„Ÿå™¨**: 6ä¸ªæ‘„åƒå¤´ã€1ä¸ªæ¿€å…‰é›·è¾¾ã€5ä¸ªæ¯«ç±³æ³¢é›·è¾¾ã€IMU/GPS
- **åœºæ™¯**: 1000ä¸ªåœºæ™¯ï¼Œ23å°æ—¶æ•°æ®

### ğŸ“Š **æ•°æ®é›†è§„æ¨¡**
| ç‰ˆæœ¬ | åœºæ™¯æ•°é‡ | æ•°æ®å¤§å° | ç”¨é€” |
|------|----------|----------|------|
| v1.0-mini | 10 | ~4GB | ğŸ¯ **æ¨èéªŒè¯é›†** |
| v1.0-trainval | 850 | ~365GB | è®­ç»ƒå’ŒéªŒè¯ |
| v1.0-test | 150 | ~75GB | æµ‹è¯• |

### ğŸš€ **å¿«é€Ÿå¼€å§‹ (æ¨è)**

#### 1. ä¸‹è½½ Mini æ•°æ®é›†
```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p /data/datasets/nuscenes

# ä¸‹è½½ mini æ•°æ®é›† (çº¦4GB)
cd /data/datasets/nuscenes
wget https://www.nuscenes.org/data/v1.0-mini.tgz
tar -xzf v1.0-mini.tgz

# ç›®å½•ç»“æ„éªŒè¯
tree -L 2 /data/datasets/nuscenes/
```

#### 2. å®‰è£…å¼€å‘å·¥å…·åŒ…
```bash
pip install nuscenes-devkit
```

#### 3. éªŒè¯å®‰è£…
```python
from nuscenes.nuscenes import NuScenes
nusc = NuScenes(version='v1.0-mini', dataroot='/data/datasets/nuscenes', verbose=True)
print(f"åœºæ™¯æ•°é‡: {len(nusc.scene)}")
print(f"æ ·æœ¬æ•°é‡: {len(nusc.sample)}")
```

### ğŸ“ **å®Œæ•´æ•°æ®é›†ä¸‹è½½**
1. **æ³¨å†Œè´¦æˆ·**: è®¿é—® [nuScenes å®˜ç½‘](https://www.nuscenes.org/)
2. **åŒæ„æ¡æ¬¾**: é˜…è¯»å¹¶åŒæ„ nuScenes Terms of Use
3. **ä¸‹è½½æ–‡ä»¶**: ä»ä¸‹è½½é¡µé¢è·å–æ‰€æœ‰æ¡£æ¡ˆæ–‡ä»¶

**å®Œæ•´æ•°æ®é›†ç»“æ„**:
```
/data/datasets/nuscenes/
â”œâ”€â”€ maps/                 # é«˜ç²¾åº¦åœ°å›¾
â”œâ”€â”€ samples/              # å…³é”®å¸§ä¼ æ„Ÿå™¨æ•°æ®
â”œâ”€â”€ sweeps/               # ä¸­é—´å¸§ä¼ æ„Ÿå™¨æ•°æ®
â”œâ”€â”€ v1.0-trainval/        # è®­ç»ƒéªŒè¯å…ƒæ•°æ®
â”œâ”€â”€ v1.0-test/            # æµ‹è¯•å…ƒæ•°æ®
â””â”€â”€ v1.0-mini/            # Mini æ•°æ®é›†å…ƒæ•°æ®
```

---

## Waymo Open Dataset

### ğŸ“‹ **æ•°æ®é›†æ¦‚è¿°**
- **å‘å¸ƒæ–¹**: Waymo LLC
- **æ•°æ®ç±»å‹**: 3D æ£€æµ‹ã€åˆ†å‰²ã€è¿åŠ¨é¢„æµ‹
- **ä¼ æ„Ÿå™¨**: 5ä¸ªæ¿€å…‰é›·è¾¾ã€5ä¸ªé«˜åˆ†è¾¨ç‡æ‘„åƒå¤´
- **åœºæ™¯**: 1,950ä¸ªåœºæ™¯ï¼Œ200,000ä¸ªæ ·æœ¬

### ğŸ“Š **æ•°æ®é›†è§„æ¨¡**
| ç‰ˆæœ¬ | åœºæ™¯æ•°é‡ | æ•°æ®å¤§å° | ç”¨é€” |
|------|----------|----------|------|
| éªŒè¯é›† | 202 | ~150GB | ğŸ¯ **æ¨èéªŒè¯é›†** |
| è®­ç»ƒé›† | 798 | ~600GB | è®­ç»ƒ |
| æµ‹è¯•é›† | 150 | ~120GB | æµ‹è¯• |

### ğŸš€ **å¿«é€Ÿå¼€å§‹**

#### 1. æ³¨å†Œå’Œæˆæƒ
```bash
# 1. è®¿é—® https://waymo.com/open/licensing/
# 2. æ³¨å†Œè´¦æˆ·å¹¶åŒæ„è®¸å¯åè®®
# 3. è·å– Google Cloud è®¿é—®æƒé™
```

#### 2. å®‰è£… API
```bash
pip install waymo-open-dataset-tf-2-11-0
# æˆ–è€…ä»æºç å®‰è£…
git clone https://github.com/waymo-research/waymo-open-dataset.git
cd waymo-open-dataset
pip install -e .
```

#### 3. ä¸‹è½½éªŒè¯å­é›† (æ¨èå¼€å§‹)
```bash
# ä½¿ç”¨ gsutil ä¸‹è½½éªŒè¯é›†çš„å‰10ä¸ªæ–‡ä»¶ (çº¦15GB)
mkdir -p /data/datasets/waymo
cd /data/datasets/waymo

# ä¸‹è½½å°å‹éªŒè¯å­é›†
gsutil -m cp gs://waymo_open_dataset_v_1_4_2/individual_files/validation/validation_0000.tfrecord .
gsutil -m cp gs://waymo_open_dataset_v_1_4_2/individual_files/validation/validation_0001.tfrecord .
# ... ç»§ç»­ä¸‹è½½æ›´å¤šæ–‡ä»¶æŒ‰éœ€
```

#### 4. ä½¿ç”¨ TensorFlow Datasets
```python
import tensorflow_datasets as tfds

# åŠ è½½å°å‹éªŒè¯é›†
dataset = tfds.load(
    'waymo_open_dataset/v1.4.2',
    split='validation[:10]',  # åªåŠ è½½å‰10ä¸ªæ ·æœ¬
    data_dir='/data/datasets/waymo'
)
```

### ğŸ“ **æ•°æ®é›†ç»“æ„**
```
/data/datasets/waymo/
â”œâ”€â”€ training/             # è®­ç»ƒ TFRecord æ–‡ä»¶
â”œâ”€â”€ validation/           # éªŒè¯ TFRecord æ–‡ä»¶
â”œâ”€â”€ testing/              # æµ‹è¯• TFRecord æ–‡ä»¶
â””â”€â”€ domain_adaptation/    # åŸŸé€‚åº”æ•°æ®
```

---

## Argoverse æ•°æ®é›†

### ğŸ“‹ **æ•°æ®é›†æ¦‚è¿°**
- **å‘å¸ƒæ–¹**: Argo AI (ç°ä¸º Ford)
- **ç‰ˆæœ¬**: Argoverse 1 å’Œ Argoverse 2
- **æ•°æ®ç±»å‹**: 3D è·Ÿè¸ªã€è¿åŠ¨é¢„æµ‹ã€åœ°å›¾é‡å»º
- **ä¼ æ„Ÿå™¨**: æ¿€å…‰é›·è¾¾ã€æ‘„åƒå¤´ã€é«˜ç²¾åº¦åœ°å›¾

### ğŸ“Š **Argoverse 2 æ•°æ®é›†è§„æ¨¡** (æ¨è)
| æ•°æ®é›† | åœºæ™¯æ•°é‡ | æ•°æ®å¤§å° | ç”¨é€” |
|--------|----------|----------|------|
| Sensor Dataset | 1,000 | ~1TB | 3D æ£€æµ‹å’Œè·Ÿè¸ª |
| Lidar Dataset | 20,000 | ~2TB | æ¿€å…‰é›·è¾¾å¤„ç† |
| Motion Forecasting | 250,000 | ~100GB | ğŸ¯ **æ¨èéªŒè¯é›†** |
| Map Change | 1,000 | ~50GB | åœ°å›¾å˜åŒ–æ£€æµ‹ |

### ğŸš€ **å¿«é€Ÿå¼€å§‹**

#### 1. å®‰è£… API
```bash
# Argoverse 2 (æ¨è)
pip install av2

# Argoverse 1 (å¦‚æœéœ€è¦)
pip install argoverse
```

#### 2. ä¸‹è½½éªŒè¯å­é›†
```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p /data/datasets/argoverse2

# ä¸‹è½½ Motion Forecasting éªŒè¯é›† (æœ€å°ï¼Œé€‚åˆå¼€å§‹)
# æ³¨æ„ï¼šéœ€è¦å…ˆåœ¨å®˜ç½‘æ³¨å†Œå¹¶è·å–ä¸‹è½½é“¾æ¥
cd /data/datasets/argoverse2

# ä½¿ç”¨å®˜æ–¹ä¸‹è½½è„šæœ¬
python -m av2.datasets.motion_forecasting.download \
    --split val \
    --target-dir /data/datasets/argoverse2 \
    --max-scenarios 100  # é™åˆ¶ä¸‹è½½æ•°é‡
```

#### 3. éªŒè¯å®‰è£…
```python
from av2.datasets.motion_forecasting import scenario_serialization

# åŠ è½½åœºæ™¯
scenario_dir = "/data/datasets/argoverse2/val"
scenario_files = list(scenario_dir.glob("*.parquet"))
print(f"æ‰¾åˆ° {len(scenario_files)} ä¸ªåœºæ™¯æ–‡ä»¶")

# åŠ è½½ç¬¬ä¸€ä¸ªåœºæ™¯
if scenario_files:
    scenario = scenario_serialization.load_argoverse_scenario_parquet(scenario_files[0])
    print(f"åœºæ™¯ID: {scenario.scenario_id}")
    print(f"è½¨è¿¹æ•°é‡: {len(scenario.tracks)}")
```

### ğŸ“ **Argoverse 2 æ•°æ®ç»“æ„**
```
/data/datasets/argoverse2/
â”œâ”€â”€ sensor/               # ä¼ æ„Ÿå™¨æ•°æ®
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ lidar/                # æ¿€å…‰é›·è¾¾æ•°æ®
â”œâ”€â”€ motion_forecasting/   # è¿åŠ¨é¢„æµ‹æ•°æ®
â””â”€â”€ map_change/           # åœ°å›¾å˜åŒ–æ•°æ®
```

---

## ç»Ÿä¸€æ•°æ®ç®¡ç†è„šæœ¬

### ğŸ› ï¸ **å®Œæ•´ä¸‹è½½è„šæœ¬** (`download_datasets.sh`)

```bash
#!/bin/bash
# è¯¦è§ claude_doc/download_datasets.sh è„šæœ¬
```

### ğŸ“Š **æ•°æ®é›†éªŒè¯è„šæœ¬** (`validate_datasets.py`)

```python
#!/usr/bin/env python3
# è¯¦è§ claude_doc/validate_datasets.py è„šæœ¬
```

---

## å­˜å‚¨ç©ºé—´è§„åˆ’

### ğŸ’¾ **æ¨èçš„æœ€å°éªŒè¯é…ç½®** (æ€»è®¡çº¦25GB)

| æ•°æ®é›† | å­é›† | å¤§å° | ç”¨é€” |
|--------|------|------|------|
| nuScenes | v1.0-mini | 4GB | æ‰€æœ‰æ¨¡å‹éªŒè¯ |
| Waymo | éªŒè¯é›†å‰10ä¸ªæ–‡ä»¶ | 15GB | å¤§è§„æ¨¡éªŒè¯ |
| Argoverse 2 | Motion Forecasting 100åœºæ™¯ | 6GB | é¢„æµ‹æ¨¡å‹éªŒè¯ |

### ğŸ—‚ï¸ **ç›®å½•ç»“æ„å»ºè®®**

```
/data/datasets/
â”œâ”€â”€ nuscenes/
â”‚   â”œâ”€â”€ v1.0-mini/           # 4GB - å¿«é€ŸéªŒè¯
â”‚   â””â”€â”€ maps/
â”œâ”€â”€ waymo/
â”‚   â”œâ”€â”€ validation/          # 15GB - å­é›†éªŒè¯
â”‚   â””â”€â”€ training/            # æŒ‰éœ€æ‰©å±•
â””â”€â”€ argoverse2/
    â”œâ”€â”€ motion_forecasting/  # 6GB - é¢„æµ‹éªŒè¯
    â””â”€â”€ sensor/              # æŒ‰éœ€æ‰©å±•
```

### âš¡ **æ€§èƒ½ä¼˜åŒ–å»ºè®®**

1. **SSD å­˜å‚¨**: æ•°æ®é›†IOå¯†é›†ï¼Œå»ºè®®ä½¿ç”¨SSD
2. **å¹¶è¡Œä¸‹è½½**: ä½¿ç”¨ `gsutil -m` æˆ– `wget -P` å¹¶è¡Œä¸‹è½½
3. **åˆ†æ‰¹éªŒè¯**: å…ˆç”¨å°æ•°æ®é›†éªŒè¯æ¨¡å‹ï¼Œå†æ‰©å±•åˆ°å®Œæ•´æ•°æ®é›†
4. **æ•°æ®ç¼“å­˜**: åœ¨å®¹å™¨ä¸­æŒ‚è½½æ•°æ®ç›®å½•ï¼Œé¿å…é‡å¤ä¸‹è½½

---

## æ•…éšœæ’é™¤

### ğŸ”§ **å¸¸è§é—®é¢˜**

1. **æƒé™é—®é¢˜**
```bash
# Waymo æ•°æ®é›†éœ€è¦ Google Cloud è®¤è¯
gcloud auth login
gcloud config set project YOUR_PROJECT_ID
```

2. **ç½‘ç»œè¶…æ—¶**
```bash
# è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
gsutil -o GSUtil:socket_timeout=300 cp gs://bucket/file .
```

3. **å­˜å‚¨ç©ºé—´ä¸è¶³**
```bash
# æ£€æŸ¥å¯ç”¨ç©ºé—´
df -h /data/datasets/
# æ¸…ç†ä¸‹è½½ç¼“å­˜
rm -rf ~/.cache/pip
```

4. **API ç‰ˆæœ¬å…¼å®¹æ€§**
```bash
# æ£€æŸ¥å·²å®‰è£…ç‰ˆæœ¬
pip list | grep -E "(nuscenes|waymo|av2)"
# æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬
pip install --upgrade nuscenes-devkit av2
```

---

## ä¸‹ä¸€æ­¥

1. **è¿è¡Œä¸‹è½½è„šæœ¬**: ä½¿ç”¨æä¾›çš„è„šæœ¬ä¸‹è½½éªŒè¯å­é›†
2. **éªŒè¯æ•°æ®å®Œæ•´æ€§**: è¿è¡ŒéªŒè¯è„šæœ¬ç¡®ä¿æ•°æ®æ­£ç¡®
3. **é›†æˆåˆ°æ¨¡å‹**: ä¿®æ”¹æ¨¡å‹é…ç½®æ–‡ä»¶æŒ‡å‘æ–°çš„æ•°æ®è·¯å¾„
4. **è¿è¡Œè¯„ä¼°**: ä½¿ç”¨å°æ•°æ®é›†æµ‹è¯•å®Œæ•´çš„è¯„ä¼°æµæ°´çº¿

å®Œæ•´çš„è‡ªåŠ¨åŒ–è„šæœ¬è¯·å‚è€ƒ `download_datasets.sh` å’Œ `validate_datasets.py`ã€‚